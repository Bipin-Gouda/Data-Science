NOTE: 
Strictly participate in kaggle discussions 
make notebooks Sundar put some effort on it


NOTE:
sklearn linear regression doesnt use Gradient Descent
Ridge and Lasso use Gradient Descent by default in sklearn ( they use Stochastic Gradient Descent)



1. What is  PCA : Principle Component Analysis :  (Feature extraction method)
ans: It is a dimensionality reduction technique -Done (just like regression Bestline,MSE,Finds which columns 
more important and when ) target is not to be scaled (target never scaled generally)

   NOTE : IN Deep Learning we have Auto Encoders & Decoders are used as PCA for dimensionality reduction in ML we 
   have to use PCA.  

2. knn imputer : Done

3. What is Gridsearch CV , its use ?
Ans: GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid.
It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting
the best parameter values, predictions are made

4. Kfold Cross validation

5. KNN, best k value selection 

6. Parameter vs Hyperparameter
- Parameter are the values that change during model training (ie .fit()) eg- m,c in regression (Y=mx+c) ,weights in NN
- Hyperparameters are values that we select and fix before training ( it remains fixed throughout training) eg alpha/lambda 
(learning rate) in Gradient descent, Ridge and Lasso

7.
It is a good practice to fit the scaler on the training data and then use it to transform the testing data. This would 
avoid any data leakage during the model testing process. Also, the scaling of target values is generally not required.


8. To Do .....
   - Time series
   - Sentiment Analysis
   - NLP